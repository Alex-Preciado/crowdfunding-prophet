{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_browser(browser=None,driver_binary=None):\n",
    "    if browser=='Safari':\n",
    "        browser = webdriver.Safari(executable_path=driver_binary);\n",
    "    if browser=='Firefox':\n",
    "        browser = webdriver.Firefox(executable_path=driver_binary);\n",
    "    if browser=='Chrome':\n",
    "        browser = webdriver.Chrome(executable_path=driver_binary);\n",
    "    \n",
    "    return browser\n",
    "\n",
    "def get_project_categories(projects_url):\n",
    "    \n",
    "    browser.get(projects_url)\n",
    "    \n",
    "    # Find the category dropdown menu\n",
    "    dropdown_menu = browser.find_element_by_class_name('cf-select__trigger')\n",
    "    #dropdown_menu.click()\n",
    "\n",
    "    # Get a list of the categories and navigate to the second one\n",
    "    category_selector = browser.find_element_by_class_name('cf-select__dropdown')\n",
    "    category_obj = category_selector.find_elements_by_tag_name('li')\n",
    "    category_list = [category.text.replace(' ','+') for category in category_obj]\n",
    "    del category_list[:1]\n",
    "    \n",
    "    return category_list\n",
    "\n",
    "def get_category_url(category):\n",
    "    \n",
    "    return 'https://www.crowdfunder.co.uk/search/projects?filter[c]='+category.replace(' ','+')\n",
    "\n",
    "def get_category_page_url(category,page):\n",
    "    get_category_url(category)+'&page='+str(page)\n",
    "    \n",
    "    return category_page_url\n",
    "\n",
    "def pages_in_category(category):\n",
    "    \n",
    "    browser.get(get_category_url(category));\n",
    "    pagination = browser.find_elements_by_css_selector('a.cf-button.cf-button--pagination')\n",
    "    page_numbers = [page.text for page in pagination]\n",
    "\n",
    "    return int(page_numbers[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of URLs to be scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all project categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Safari web driver\n",
    "browser = start_browser('Safari','/usr/bin/safaridriver')\n",
    "\n",
    "# Here we get:\n",
    "# - The list of all the available project categories in www.crowdfunder.co.uk,\n",
    "# - The urls of each category.\n",
    "categories = get_project_categories('https://www.crowdfunder.co.uk/search/projects')\n",
    "categories_urls = [get_category_url(category) for category in categories]\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community,  \tBusiness,  \tCharities,  \tArts,  \tFilm+and+Theatre,  \tSocial+Enterprise,  \tMusic,  \tPolitics,  \tSchools,  \tSports,  \tPersonal+Causes,  \tTechnology,  \tFood+and+Drink,  \tEnvironment,  \tUniversity,  \tPublishing,  \tCommunity+shares,  \tHeritage,  \t"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.crowdfunder.co.uk/search/projects?filter[c]=Community',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Business',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Charities',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Arts',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Film+and+Theatre',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Social+Enterprise',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Music',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Politics',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Schools',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Sports',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Personal+Causes',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Technology',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Food+and+Drink',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Environment',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=University',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Publishing',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Community+shares',\n",
       " 'https://www.crowdfunder.co.uk/search/projects?filter[c]=Heritage']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the list of all categories\n",
    "for cat in categories[0:20]:\n",
    "    print(cat, end=',  \\t')\n",
    "\n",
    "# And the corresponding URLs\n",
    "categories_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all Project Search results pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community has 42 pages\n",
      "Business has 42 pages\n",
      "Charities has 42 pages\n",
      "Arts has 42 pages\n",
      "Film+and+Theatre has 42 pages\n",
      "Social+Enterprise has 42 pages\n",
      "Music has 42 pages\n",
      "Politics has 42 pages\n",
      "Schools has 42 pages\n",
      "Sports has 42 pages\n",
      "Personal+Causes has 42 pages\n",
      "Technology has 42 pages\n",
      "Food+and+Drink has 40 pages\n",
      "Environment has 32 pages\n",
      "University has 28 pages\n",
      "Publishing has 19 pages\n",
      "Community+shares has 10 pages\n",
      "Heritage has 4 pages\n"
     ]
    }
   ],
   "source": [
    "# Load the Safari web driver\n",
    "browser = start_browser('Safari','/usr/bin/safaridriver')\n",
    "\n",
    "cat_pages_urls = []\n",
    "all_cats_pages_urls = []\n",
    "\n",
    "for category in categories:\n",
    "    for page in range(1,pages_in_category(category)+1):\n",
    "        cat_pages_urls.append(get_category_url(category)+'&page='+str(page))\n",
    "    \n",
    "    print(category,'has',pages_in_category(category),'pages')\n",
    "    \n",
    "    temp_list = cat_pages_urls.copy()\n",
    "    all_cats_pages_urls.append(temp_list)\n",
    "    cat_pages_urls.clear()\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Community&page=1\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Community&page=2\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Community&page=3\n",
      "...\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Business&page=1\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Business&page=2\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Business&page=3\n",
      "...\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Charities&page=1\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Charities&page=2\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Charities&page=3\n",
      "...\n",
      "...\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Heritage&page=3\n",
      "https://www.crowdfunder.co.uk/search/projects?filter[c]=Heritage&page=4\n"
     ]
    }
   ],
   "source": [
    "# And now we have a list of all search pages per category\n",
    "for i in range(0,3):\n",
    "    for url in all_cats_pages_urls[i][0:3]:\n",
    "        print(url)\n",
    "    print('...')\n",
    "\n",
    "print('...')\n",
    "print(all_cats_pages_urls[-1][-2])\n",
    "print(all_cats_pages_urls[-1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focusing on \"Community\" projects. List of all campaigns URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting all URLs from https://www.crowdfunder.co.uk/search/projects?filter[c]=Community&page=1\n",
      "Getting all URLs from https://www.crowdfunder.co.uk/search/projects?filter[c]=Community&page=2\n",
      "Getting all URLs from https://www.crowdfunder.co.uk/search/projects?filter[c]=Community&page=3\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# We use the previous list of search pages to get the URLS of\n",
    "# all the campaigns in all the categories\n",
    "\n",
    "# IMPORTANT NOTE: to get started let's focus on the *Community* campaigns\n",
    "community_pages_urls = all_cats_pages_urls[0]\n",
    "\n",
    "browser = start_browser('Safari','/usr/bin/safaridriver')\n",
    "\n",
    "# Initialize list to save all community project\n",
    "community_campaigns_urls = [];\n",
    "for page_url in community_pages_urls:\n",
    "    \n",
    "    if page_url in community_pages_urls[0:3]:\n",
    "        print('Getting all URLs from',page_url)\n",
    "    \n",
    "    browser.get(page_url)\n",
    "    urls_obj = browser.find_elements_by_css_selector('a.cf-pod__image')\n",
    "    campaigns_hrefs = [item.get_attribute('href') for item in urls_obj]\n",
    "    community_campaigns_urls.extend(campaigns_hrefs)\n",
    "    \n",
    "    time.sleep(3)\n",
    "\n",
    "print('\\n...')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the first then Community projects ...\n",
      "\n",
      "https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign\n",
      "https://www.crowdfunder.co.uk/barra-distillery-share-offer\n",
      "https://www.crowdfunder.co.uk/punl-cgp\n",
      "https://www.crowdfunder.co.uk/highland-bagpipe-centre\n",
      "https://www.crowdfunder.co.uk/northfieldartsforum\n",
      "https://www.crowdfunder.co.uk/somerford-youth-and-community-centre\n",
      "https://www.crowdfunder.co.uk/lets-build-a-broch\n",
      "https://www.crowdfunder.co.uk/cardinal-fm\n",
      "https://www.crowdfunder.co.uk/midsteeple-quarter\n",
      "https://www.crowdfunder.co.uk/stop-funding-hate-lock-in-the-change\n",
      "...\n",
      "...\n",
      "There are 1000 Community campaigns in total\n"
     ]
    }
   ],
   "source": [
    "# Here's the list of URLs of the first then Community projects\n",
    "#\n",
    "print('Here are the first then Community projects ...\\n')\n",
    "for campaign in community_campaigns_urls[0:10]:\n",
    "    print(campaign)\n",
    "\n",
    "print('...\\n...\\nThere are',len(community_campaigns_urls),'Community campaigns in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Community Campaigns info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's initialize lists to save all the pledges, with their corresponding\n",
    "# dates and supporter names. \n",
    "total_pledges = []\n",
    "total_dates = []\n",
    "total_names = []\n",
    "\n",
    "# Let's also initialize a counter to keep track of the total number of\n",
    "# campaigns saved\n",
    "Ncampaigns = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=2#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=3#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=4#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=5#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=6#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=7#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=8#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=9#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=10#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=11#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=12#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=13#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=14#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=15#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=16#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=17#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=18#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=19#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=20#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=21#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=22#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=23#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=24#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=25#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=26#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lady-astor-statue-100-campaign/backers?page=27#start\n",
      "Scraping: https://www.crowdfunder.co.uk/barra-distillery-share-offer/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/punl-cgp/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/punl-cgp/backers?page=2#start\n",
      "Scraping: https://www.crowdfunder.co.uk/highland-bagpipe-centre/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/highland-bagpipe-centre/backers?page=2#start\n",
      "Scraping: https://www.crowdfunder.co.uk/highland-bagpipe-centre/backers?page=3#start\n",
      "Scraping: https://www.crowdfunder.co.uk/highland-bagpipe-centre/backers?page=4#start\n",
      "Scraping: https://www.crowdfunder.co.uk/northfieldartsforum/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/northfieldartsforum/backers?page=2#start\n",
      "Scraping: https://www.crowdfunder.co.uk/northfieldartsforum/backers?page=3#start\n",
      "Scraping: https://www.crowdfunder.co.uk/somerford-youth-and-community-centre/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=2#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=3#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=4#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=5#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=6#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=7#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=8#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=9#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=10#start\n",
      "Scraping: https://www.crowdfunder.co.uk/lets-build-a-broch/backers?page=11#start\n",
      "Scraping: https://www.crowdfunder.co.uk/cardinal-fm/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/midsteeple-quarter/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/midsteeple-quarter/backers?page=2#start\n",
      "Scraping: https://www.crowdfunder.co.uk/midsteeple-quarter/backers?page=3#start\n",
      "Scraping: https://www.crowdfunder.co.uk/midsteeple-quarter/backers?page=4#start\n",
      "Scraping: https://www.crowdfunder.co.uk/midsteeple-quarter/backers?page=5#start\n",
      "Scraping: https://www.crowdfunder.co.uk/stop-funding-hate-lock-in-the-change/backers\n",
      "Scraping: https://www.crowdfunder.co.uk/stop-funding-hate-lock-in-the-change/backers?page=2#start\n",
      "Scraping: https://www.crowdfunder.co.uk/stop-funding-hate-lock-in-the-change/backers?page=3#start\n",
      "Scraping: https://www.crowdfunder.co.uk/stop-funding-hate-lock-in-the-change/backers?page=4#start\n",
      "Scraping: https://www.crowdfunder.co.uk/stop-funding-hate-lock-in-the-change/backers?page=5#start\n",
      "Scraping: https://www.crowdfunder.co.uk/stop-funding-hate-lock-in-the-change/backers?page=6#start\n",
      "Scraping: https://www.crowdfunder.co.uk/stop-funding-hate-lock-in-the-change/backers?page=7#start\n"
     ]
    }
   ],
   "source": [
    "browser = start_browser('Safari','/usr/bin/safaridriver')\n",
    "\n",
    "for campaign_url in community_campaigns_urls[0:10]:\n",
    "    \n",
    "    browser.get(campaign_url+'/backers')\n",
    "    \n",
    "    pledges = []\n",
    "    dates = []\n",
    "    names = []\n",
    "    more_supporters = True\n",
    "    \n",
    "    while more_supporters==True:\n",
    "        print('Scraping:',browser.current_url)\n",
    "        time.sleep(3)\n",
    "        soup = BeautifulSoup(browser.page_source,'html.parser')\n",
    "\n",
    "        tags = soup.find_all('article',{'class':'cf-well', 'data-well':'plain', 'data-well-spacing':'vertical'})\n",
    "\n",
    "        for tag in tags:\n",
    "            #print(tag.find(\"span\", class_=\"cf-text--light\").string.split()[-1][1:])\n",
    "            pledges.append(float(tag.find(\"span\", class_=\"cf-text--light\").string.split()[-1][1:].replace(',','')))\n",
    "\n",
    "        for tag in tags:\n",
    "            #print(tag.find(\"p\", class_=\"cf-text\").string)\n",
    "            dates.append(tag.find(\"p\", class_=\"cf-text\").string)\n",
    "\n",
    "        for tag in tags:\n",
    "            #print(tag.find(\"a\"))\n",
    "            if tag.find(\"a\")==None:\n",
    "                #print('Anonymous')\n",
    "                names.append('Anonymous')\n",
    "            else:\n",
    "                #print(tag.find(\"a\").string)\n",
    "                names.append(tag.find(\"a\").string)\n",
    "\n",
    "        button = soup.find('a',{'class':'cf-button cf-button--small cf-button--hollow', 'data-icon-button':'next'})\n",
    "\n",
    "        if button is None:\n",
    "            more_supporters = False;\n",
    "        if button is not None:\n",
    "            browser.get(campaign_url+'/backers'+button['href'])\n",
    "        \n",
    "    total_pledges.append(pledges)\n",
    "    total_dates.append(dates)\n",
    "    total_names.append(names)\n",
    "    Ncampaigns += 1\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many campaigns were scraped\n",
    "len(total_pledges), len(total_dates), len(total_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([750.0, 1500.0, 1000.0, 750.0, 750.0, 1000.0, 300.0, 250.0, 250.0, 250.0],\n",
       " ['Anonymous',\n",
       "  'Kevin MacNeil',\n",
       "  'Werner Henssen',\n",
       "  'David Cott',\n",
       "  'Juergen Roemer',\n",
       "  'Roland Wirth',\n",
       "  'johannes hoyme',\n",
       "  'Stefan Dahlmann',\n",
       "  'FUMIKAZU SAWA',\n",
       "  'Patrick Sackermann'],\n",
       " ['29th January 2019 00:22',\n",
       "  '26th January 2019 17:43',\n",
       "  '15th January 2019 17:54',\n",
       "  '15th January 2019 14:13',\n",
       "  '14th January 2019 08:53',\n",
       "  '13th January 2019 16:22',\n",
       "  '13th January 2019 10:32',\n",
       "  '10th January 2019 10:40',\n",
       "  '10th January 2019 04:44',\n",
       "  '9th January 2019 07:06'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = total_names.copy()\n",
    "dlist = total_dates.copy()\n",
    "plist = total_pledges.copy()\n",
    "\n",
    "plist[1][0:10], nlist[1][0:10], dlist[1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>supporter name</th>\n",
       "      <th>pledge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21st December 2018 15:07</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21st December 2018 15:14</td>\n",
       "      <td>Alexander Clark</td>\n",
       "      <td>888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21st December 2018 19:12</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24th December 2018 09:13</td>\n",
       "      <td>Peter Jeffs</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24th December 2018 09:34</td>\n",
       "      <td>Dirk Tinbergen</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30th December 2018 13:18</td>\n",
       "      <td>John</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30th December 2018 21:38</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd January 2019 14:24</td>\n",
       "      <td>Peter Scheurer</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4th January 2019 14:52</td>\n",
       "      <td>Arnfinn Stake</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7th January 2019 12:27</td>\n",
       "      <td>Duncan Tait</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8th January 2019 17:45</td>\n",
       "      <td>JASON OH</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8th January 2019 20:06</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9th January 2019 01:41</td>\n",
       "      <td>Claude Cyr</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9th January 2019 07:06</td>\n",
       "      <td>Patrick Sackermann</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10th January 2019 04:44</td>\n",
       "      <td>FUMIKAZU SAWA</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10th January 2019 10:40</td>\n",
       "      <td>Stefan Dahlmann</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13th January 2019 10:32</td>\n",
       "      <td>johannes hoyme</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13th January 2019 16:22</td>\n",
       "      <td>Roland Wirth</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14th January 2019 08:53</td>\n",
       "      <td>Juergen Roemer</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15th January 2019 14:13</td>\n",
       "      <td>David Cott</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15th January 2019 17:54</td>\n",
       "      <td>Werner Henssen</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26th January 2019 17:43</td>\n",
       "      <td>Kevin MacNeil</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29th January 2019 00:22</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date      supporter name  pledge\n",
       "0   21st December 2018 15:07           Anonymous   750.0\n",
       "1   21st December 2018 15:14     Alexander Clark   888.0\n",
       "2   21st December 2018 19:12           Anonymous   500.0\n",
       "3   24th December 2018 09:13         Peter Jeffs  2500.0\n",
       "4   24th December 2018 09:34      Dirk Tinbergen   750.0\n",
       "5   30th December 2018 13:18               John    750.0\n",
       "6   30th December 2018 21:38           Anonymous   800.0\n",
       "7     2nd January 2019 14:24      Peter Scheurer   750.0\n",
       "8     4th January 2019 14:52       Arnfinn Stake   250.0\n",
       "9     7th January 2019 12:27         Duncan Tait   750.0\n",
       "10    8th January 2019 17:45            JASON OH   750.0\n",
       "11    8th January 2019 20:06           Anonymous  4000.0\n",
       "12    9th January 2019 01:41          Claude Cyr   250.0\n",
       "13    9th January 2019 07:06  Patrick Sackermann   250.0\n",
       "14   10th January 2019 04:44       FUMIKAZU SAWA   250.0\n",
       "15   10th January 2019 10:40     Stefan Dahlmann   250.0\n",
       "16   13th January 2019 10:32      johannes hoyme   300.0\n",
       "17   13th January 2019 16:22        Roland Wirth  1000.0\n",
       "18   14th January 2019 08:53      Juergen Roemer   750.0\n",
       "19   15th January 2019 14:13          David Cott   750.0\n",
       "20   15th January 2019 17:54      Werner Henssen  1000.0\n",
       "21   26th January 2019 17:43       Kevin MacNeil  1500.0\n",
       "22   29th January 2019 00:22           Anonymous   750.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict = {}\n",
    "\n",
    "for i in range(len(plist)):\n",
    "    df_temp = pd.DataFrame(\n",
    "        {'date': dlist[i][::-1],\n",
    "         'supporter name': nlist[i][::-1],\n",
    "         'pledge': plist[i][::-1]\n",
    "        })\n",
    "    df_dict.update( {'campaign'+'{0:0=4d}'.format(i) : df_temp} )\n",
    "    df_temp.to_csv('campaign'+'{0:0=4d}'.format(i)+'.csv')\n",
    "    \n",
    "df_dict['campaign0001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
